{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ryerson University $~~~~~~~~~~~~~~~~~~~~~~~~~~~$ $~~~~~~~~~~~~~~~~~~~~~~~~$ Laboratory of Innovations in Transportation (LiTans)\n",
    "$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$ \n",
    "$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$\n",
    "$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$ \n",
    "$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$ \n",
    "\n",
    "# <center> <font color='royalblue'> “Impacts of the COVID-19 Pandemic on Ridesourcing Services in Small Towns and Large Cities”</font> </center> \n",
    "\n",
    "# <center> <font color='royalblue'> Part Two: Percent Reduction in Daily Demand Model </font> </center> \n",
    "\n",
    "\n",
    "$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$ \n",
    "$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$\n",
    "\n",
    "# <center>Nael Alsaleh & Bilal Farooq </center>\n",
    "$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$\n",
    "# January 2022"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inputs\n",
    "\n",
    "1. Modelling dataset that includes all the variables shown below.\n",
    "\n",
    "Month, Day_of_week, Weekend, Cases, Deaths, Hospitalizations, Positive_Rate, Partially_Vaccinated, Fully_Vaccinated, Stringency_Index, and Per_Reduction "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dependencies\r\n",
    "\r\n",
    "In order to run this code successfully, you will need to:\r\n",
    "1. Latest version of Python\r\n",
    "2. Installing the required libraries."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implementation\n",
    "\n",
    "The implementation of the direct demand model has been divided into two parts:\n",
    "\n",
    "1. Modelling\n",
    "2. Model Interpretation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color='forestgreen'> Part 1. Modelling </font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A) Import the required packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "B) Import the Training Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Demand_Reduction_Data = pd.read_csv('Reduction_Daily_Demand_Chicago.csv')\n",
    "\n",
    "# Define the explanatory and response variables\n",
    "X = Demand_Reduction_Data[['Month', 'Day_of_week', 'Weekend', 'Cases', 'Deaths', 'Hospitalizations', 'Positive_Rate', \n",
    "                           'Partially_Vaccinated', 'Fully_Vaccinated', 'Stringency_Index']]\n",
    "\n",
    "Y = Demand_Reduction_Data['Per_Reduction']\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, test_size = 0.20, \n",
    "random_state = 101)\n",
    "\n",
    "# Print the shape of training and testing datasets\n",
    "print (X_Train.shape)\n",
    "print (Y_Train.shape)\n",
    "print (X_Test.shape)\n",
    "print (Y_Test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "C) Find the optimum Hyperparameters for the Trip Distribution Model (Random Forest Model) using Bayesian Optimization Method"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "space = {'criterion': hp.choice('criterion', ['squared_error', 'absolute_error']),\n",
    "        'max_depth': hp.quniform('max_depth', 10, 150, 10),\n",
    "        'max_features': hp.choice('max_features', ['auto', 'sqrt','log2']),\n",
    "        'min_samples_leaf': hp.uniform ('min_samples_leaf', 0, 0.5),\n",
    "        'min_samples_split' : hp.uniform ('min_samples_split', 0, 1),\n",
    "        'n_estimators' : hp.choice('n_estimators', [10, 50, 100, 150, 300]),\n",
    "        'max_leaf_nodes' : hp.choice('max_leaf_nodes', [10, 50, 100, 150, 300, None]),\n",
    "        'bootstrap' : hp.choice('bootstrap', [True, False])\n",
    "         }\n",
    "def objective(space):\n",
    "    model = RandomForestRegressor(criterion = space['criterion'], \n",
    "                                  max_depth = space['max_depth'],\n",
    "                                  max_features = space['max_features'],\n",
    "                                  min_samples_leaf = space['min_samples_leaf'],\n",
    "                                  min_samples_split = space['min_samples_split'],\n",
    "                                  n_estimators = space['n_estimators'],\n",
    "                                  max_leaf_nodes =space['max_leaf_nodes'],\n",
    "                                  bootstrap = space['bootstrap'],\n",
    "                                 )\n",
    "    \n",
    "    scores = cross_val_score(model, X_Train, Y_Train, cv = 5, scoring='neg_mean_squared_error').mean() \n",
    "    #return scores.mean()\n",
    "    return {'loss': - scores, 'status': STATUS_OK }\n",
    "    \n",
    "trials = Trials()\n",
    "best = fmin(fn= objective,\n",
    "            space= space,\n",
    "            algo= tpe.suggest,\n",
    "            max_evals = 100,\n",
    "            trials= trials)\n",
    "best"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "D)  Apply the optimal  architectures  of  the  algorithms  on  the  testing  set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "crit = {0: 'squared_error', 1: 'absolute_error'}\n",
    "feat = {0: 'auto', 1: 'sqrt', 2: 'log2'}\n",
    "est = {0: 10, 1: 50, 2: 100,  3: 150, 4:300}\n",
    "leaf_node = {0: 10, 1: 50, 2: 100, 3: 150, 4: 300, 5: None}\n",
    "boot = {0: True, 1: False}\n",
    "\n",
    "trainedforest = RandomForestRegressor( criterion = crit[best['criterion']], \n",
    "                                       max_depth = best['max_depth'], \n",
    "                                       max_features = feat[best['max_features']], \n",
    "                                       min_samples_leaf = best['min_samples_leaf'], \n",
    "                                       min_samples_split = best['min_samples_split'], \n",
    "                                       n_estimators = est[best['n_estimators']], \n",
    "                                       max_leaf_nodes = leaf_node[best['max_leaf_nodes']],\n",
    "                                       bootstrap = boot[best['bootstrap']]\n",
    "                                      ).fit(X_Train,Y_Train)\n",
    "\n",
    "predictionforest = trainedforest.predict(X_Test)\n",
    "\n",
    "y_true = Y_Test # Your real values / test labels\n",
    "y_pred = predictionforest # The predictions from your ML / RF model\n",
    "\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_true, y_pred))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_true, y_pred))\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_true, y_pred)))\n",
    "print('R^2:', metrics.r2_score(y_true, y_pred))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color='forestgreen'> Part 2: Model Interpretation Using SHAP (SHapley  Additive  exPlanations)</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_Test_new = pd.DataFrame(X_Test, columns = ['Month', 'Day_of_week', 'Weekend', 'Cases', 'Deaths', 'Hospitalizations', 'Positive_Rate', \n",
    "                                             'Partially_Vaccinated', 'Fully_Vaccinated', 'Stringency_Index'])\n",
    "\n",
    "import shap\n",
    "X_train_summary = shap.kmeans(X_Train, 5)\n",
    "\n",
    "\n",
    "rf_explainer_ = shap.KernelExplainer(trainedforest.predict,X_train_summary, nsamples=100)\n",
    "rf_shap_values_ = rf_explainer_.shap_values(X_Test_new)\n",
    "\n",
    "shap.summary_plot(rf_shap_values_, X_Test_new, show=False, max_display=X.shape[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "1e804ed476d24b1c6d6c91634a5e59520f27170f52bbab5fd8926b3552ceeee3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}